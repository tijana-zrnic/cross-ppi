{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021c9654",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os, sys\n",
    "sys.path.insert(1, '../')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import expit\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import pdb\n",
    "from scipy.stats import norm\n",
    "import matplotlib.patheffects as pe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5a9aec",
   "metadata": {},
   "source": [
    "## Read and preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424b8f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read raw data\n",
    "raw_df = pd.read_csv('./data.csv')\n",
    "\n",
    "# Process raw data\n",
    "df = raw_df[raw_df.Year1 != 'tdo'].copy()\n",
    "df.Year1 = df.Year1.astype(float)\n",
    "\n",
    "\n",
    "Y_all = (((df.Type1.astype(str) != 'nan') & ((df.Year1 >= 2000) & (df.Year1 <= 2015))) |\n",
    "      ((df.Type2.astype(str) != 'nan') & ((df.Year2 >= 2000) & (df.Year2 <= 2015))) |\n",
    "      ((df.Type3.astype(str) != 'nan') & ((df.Year3 >= 2000) & (df.Year3 <= 2015))) ).astype(float).to_numpy()\n",
    "\n",
    "X_all = np.stack([\n",
    "        df.tree_canopy_cover_2015/100,\n",
    "        df.tree_canopy_cover_2000/100\n",
    "    ], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744078a3",
   "metadata": {},
   "source": [
    "## Implementation of classical inference, PPI with data splitting, and cross-prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19db17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trial(X, Y, n, alpha):\n",
    "    # one trial; randomly splits data into labeled and unlabeled data and then runs baselines\n",
    "    \n",
    "    X_labeled, X_unlabeled, Y_labeled, Y_unlabeled = train_test_split(X, Y, train_size=n)\n",
    "\n",
    "    classical_interval = classical_mean_interval(Y_labeled, alpha) # uses only labeled data\n",
    "    \n",
    "    pp_interval = pp_mean_interval(X_labeled, X_unlabeled, Y_labeled, alpha, int(0.1*n)) # runs PPI after data splitting\n",
    "    \n",
    "    cpp_interval = cross_prediction_mean_interval(X_labeled, X_unlabeled, Y_labeled, alpha) # cross-prediction\n",
    "\n",
    "    return classical_interval, pp_interval, cpp_interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12e5208",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pp_mean_interval(X_labeled, X_unlabeled, Y_labeled, alpha, n_tr):\n",
    "    # performs data splitting and then runs PPI with CLT interval\n",
    "    \n",
    "    n = X_labeled.shape[0]\n",
    "    N = X_unlabeled.shape[0]\n",
    "    \n",
    "    X_train, X_val, Y_train, Y_val = train_test_split(X_labeled, Y_labeled, train_size=n_tr)\n",
    "    \n",
    "\n",
    "    \n",
    "    cls = HistGradientBoostingClassifier(max_iter=100,max_depth=2).fit(\n",
    "            X_train,\n",
    "            Y_train\n",
    "        )\n",
    "    Yhat_unlabeled = cls.predict_proba(X_unlabeled)[:,1]\n",
    "    Yhat_val = cls.predict_proba(X_val)[:,1]\n",
    "    \n",
    "    thetaPP = np.mean(Yhat_unlabeled) + np.mean(Y_val - Yhat_val)\n",
    "    \n",
    "    sigma_hat = np.sqrt(np.var(Yhat_unlabeled)/N + np.var(Y_val - Yhat_val)/(n - n_tr))\n",
    "    \n",
    "    halfwidth = norm.ppf(1-alpha/2) * sigma_hat\n",
    "    \n",
    "    return [thetaPP - halfwidth, thetaPP + halfwidth]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1346f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_prediction_mean_interval(X_labeled, X_unlabeled, Y_labeled, alpha, K = 10):\n",
    "    # cross-prediction\n",
    "    \n",
    "    n = X_labeled.shape[0]\n",
    "    N = X_unlabeled.shape[0]\n",
    "    \n",
    "    fold_n = int(n/K)\n",
    "    \n",
    "    Yhat_labeled = np.zeros(n)\n",
    "    Yhat_unlabeled = np.zeros(N)\n",
    "    Yhat_avg_labeled = np.zeros(n)\n",
    "    \n",
    "    for j in range(K):\n",
    "    \n",
    "        X_val = X_labeled[j*fold_n:(j+1)*fold_n,:]\n",
    "        Y_val = Y_labeled[j*fold_n:(j+1)*fold_n]\n",
    "        train_ind = np.delete(range(n),range(j*fold_n,(j+1)*fold_n))\n",
    "        X_train = X_labeled[train_ind,:]\n",
    "        Y_train = Y_labeled[train_ind]\n",
    "\n",
    "        # use train data to train a classifier\n",
    "        cls = HistGradientBoostingClassifier(max_iter=100,max_depth=2).fit(\n",
    "            X_train,\n",
    "            Y_train\n",
    "        )\n",
    "\n",
    "\n",
    "        Yhat_unlabeled += cls.predict_proba(X_unlabeled)[:,1]/K\n",
    "        Yhat_labeled[j*fold_n:(j+1)*fold_n] = cls.predict_proba(X_val)[:,1]\n",
    "    \n",
    "    \n",
    "    thetaPP = np.mean(Yhat_unlabeled) + np.mean(Y_labeled - Yhat_labeled)\n",
    "\n",
    "\n",
    "    var_hat = bootstrap_variance(X_labeled, X_unlabeled, Y_labeled, n-fold_n, thetaPP)\n",
    "    \n",
    "    \n",
    "    halfwidth = norm.ppf(1-alpha/2) * np.sqrt(var_hat)\n",
    "    \n",
    "    return [thetaPP - halfwidth, thetaPP + halfwidth]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8056b772",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_variance(X_labeled, X_unlabeled, Y_labeled, train_n, thetaPP, B = 30):\n",
    "    # estimates the asymptotic variance of cross-prediction\n",
    "    \n",
    "    \n",
    "    n = X_labeled.shape[0]\n",
    "    N = X_unlabeled.shape[0]\n",
    "\n",
    "    Yhat_labeled = np.zeros(n)\n",
    "    Yhat_unlabeled = np.zeros(N)\n",
    "    \n",
    "    \n",
    "    grad_diff = np.zeros(int((n-train_n)*B))\n",
    "    \n",
    "    for j in range(B):\n",
    "        \n",
    "        train_ind = np.random.choice(range(n),train_n)\n",
    "        X_train = X_labeled[train_ind,:]\n",
    "        Y_train = Y_labeled[train_ind]\n",
    "        \n",
    "        # use train data to train a classifier\n",
    "        cls = HistGradientBoostingClassifier(max_iter=100,max_depth=2).fit(\n",
    "            X_train,\n",
    "            Y_train\n",
    "        )\n",
    "\n",
    "\n",
    "        Yhat_unlabeled += cls.predict_proba(X_unlabeled)[:,1]/B\n",
    "        \n",
    "        other_inds = np.delete(range(n), train_ind)[:n-train_n]\n",
    "        Yhat_labeled = cls.predict_proba(X_labeled[other_inds,:])[:,1]\n",
    "\n",
    "        grad_diff[j*(n-train_n):(j+1)*(n-train_n)] = Yhat_labeled - Y_labeled[other_inds]\n",
    "    \n",
    "    var_unlabeled = np.var(Yhat_unlabeled)\n",
    "    var_labeled = np.var(grad_diff)\n",
    "    \n",
    "    var_hat = var_unlabeled/N + var_labeled/n\n",
    "    \n",
    "    return var_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c877d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classical_mean_interval(Y, alpha):\n",
    "    # classical CLT interval\n",
    "    n = len(Y)\n",
    "    point_estimate = np.mean(Y)\n",
    "    halfwidth = norm.ppf(1-alpha/2) * np.sqrt(np.var(Y)/n)\n",
    "    return [point_estimate - halfwidth, point_estimate + halfwidth]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57dc768f",
   "metadata": {},
   "source": [
    "## Construct confidence intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4c31ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_trials = 100\n",
    "alpha = 0.1\n",
    "ps = [0.1, 0.2, 0.3] # fraction of data with labels\n",
    "\n",
    "theta_true = np.mean(Y_all)\n",
    "\n",
    "df_list = []\n",
    "        \n",
    "# store results\n",
    "columns = [\"lb\",\"ub\",\"coverage\",\"estimator\",\"n\"]\n",
    "\n",
    "filename = \"./deforestation_results/simulation_results.csv\"\n",
    "\n",
    "results = []\n",
    "\n",
    "for p in ps:\n",
    "        \n",
    "        n = int(p*len(Y_all))\n",
    "        print(n)\n",
    "\n",
    "        \n",
    "        for i in range(num_trials):\n",
    "            ci, ppi, cppi = trial(X_all, Y_all, n, alpha)\n",
    "                \n",
    "            temp_df = pd.DataFrame(np.zeros((3,len(columns))), columns=columns)\n",
    "            temp_df.loc[0] = cppi[0], cppi[1], (cppi[0] <= theta_true) & (theta_true <= cppi[1]), \"cross-prediction\", n\n",
    "            temp_df.loc[1] = ci[0], ci[1], (ci[0] <= theta_true) & (theta_true <= ci[1]), \"classical\", n\n",
    "            temp_df.loc[2] = ppi[0], ppi[1], (ppi[0] <= theta_true) & (theta_true <= ppi[1]), \"PPI\", n\n",
    "            results += [temp_df]\n",
    "\n",
    "df = pd.concat(results)\n",
    "df[\"width\"] = df[\"ub\"] - df[\"lb\"]\n",
    "df_list += [df]\n",
    "os.makedirs('./deforestation_results/', exist_ok=True)\n",
    "        \n",
    "final_df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "# save data\n",
    "final_df.to_csv(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f7b5a4",
   "metadata": {},
   "source": [
    "## Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540bcd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha=0.1\n",
    "col = np.array([sns.color_palette(\"Set2\")[1], sns.color_palette(\"Set2\")[2], sns.color_palette(\"Set2\")[0], sns.color_palette(\"Set2\")[3], sns.color_palette(\"Set2\")[4]])\n",
    "sns.set_theme(font_scale=1.4, style='white', palette=col, rc={'lines.linewidth': 3})\n",
    "# defaults = {'n': 100, 'beta': 0}\n",
    "fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(10,3.3))\n",
    "sns.lineplot(ax=axs[0],data=final_df, x='n', y='coverage', hue='estimator', alpha=0.9, errorbar=None, marker=\"*\", markersize=14)\n",
    "sns.lineplot(ax=axs[1],data=final_df, x='n', y='width', hue='estimator', alpha=0.9, marker=\"*\", markersize=14)\n",
    "\n",
    "axs[0].axhline(1-alpha, color=\"#888888\", linestyle='dashed', zorder=1, alpha=0.9)\n",
    "handles, labels = axs[1].get_legend_handles_labels()\n",
    "axs[1].legend(handles=handles, labels=labels)\n",
    "axs[0].get_legend().remove()\n",
    "axs[0].set_ylim([0.0,1])\n",
    "\n",
    "for i in [0,1]:\n",
    "    for j in range(3):\n",
    "        axs[i].lines[j].set_linestyle(\"--\")\n",
    "\n",
    "sns.despine(top=True, right=True)\n",
    "plt.tight_layout()\n",
    "\n",
    "# save plot\n",
    "plt.savefig('./deforestation_results/deforestation_comparison.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad1ea02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for reading data after it has been saved\n",
    "datadir = './deforestation_results/'\n",
    "filenames = os.listdir(datadir)\n",
    "data = [ pd.read_csv(os.path.join(datadir, fn)) for fn in filenames if 'simulation_results.' in fn ]\n",
    "final_df = pd.concat(data, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2325cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_ints = 5\n",
    "inds = np.random.choice(num_trials, num_ints)\n",
    "CPPI_ints = []\n",
    "PPI_ints = []\n",
    "classical_ints = []\n",
    "n = 319\n",
    "\n",
    "for i in range(num_ints):\n",
    "    ind = inds[i]\n",
    "    CPPI_ints.append([final_df[(final_df.estimator == \"cross-prediction\") & (final_df.n == n)].iloc[ind].lb, final_df[(final_df.estimator == \"cross-prediction\") & (final_df.n == n)].iloc[ind].ub])\n",
    "    PPI_ints.append([final_df[(final_df.estimator == \"PPI\") & (final_df.n == n)].iloc[ind].lb, final_df[(final_df.estimator == \"PPI\") & (final_df.n == n)].iloc[ind].ub])\n",
    "    classical_ints.append([final_df[(final_df.estimator == \"classical\") & (final_df.n == n)].iloc[ind].lb, final_df[(final_df.estimator == \"classical\") & (final_df.n == n)].iloc[ind].ub])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5f1107",
   "metadata": {},
   "source": [
    "## Intro figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af69fa15",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha=0.1\n",
    "\n",
    "gap = 0.03\n",
    "start1 = 0.5\n",
    "start2 = 0.35\n",
    "start3 = 0.2\n",
    "linewidth_inner = 5\n",
    "linewidth_outer = 7\n",
    "\n",
    "k = len(CPPI_ints)\n",
    "\n",
    "col = np.array([sns.color_palette(\"Set2\")[1], sns.color_palette(\"Set2\")[2],  sns.color_palette(\"Set2\")[0]])\n",
    "sns.set_theme(font_scale=1.4, style='white', palette=col, rc={'lines.linewidth': 3})\n",
    "\n",
    "fig, axs = plt.subplots(nrows=1, ncols=3, figsize=(15,3.3))\n",
    "\n",
    "\n",
    "axs[0].axvline(theta_true, color='gray', linestyle='dashed')\n",
    "\n",
    "for i in reversed(range(k)):\n",
    "    \n",
    "    if i == 0:\n",
    "        axs[0].plot([CPPI_ints[i][0] , CPPI_ints[i][1] ],[start1+i*gap,start1+i*gap], linewidth=linewidth_inner, color=lighten_color(col[0],0.6), path_effects=[pe.Stroke(linewidth=linewidth_outer, offset=(-1,0), foreground=col[0]), pe.Stroke(linewidth=linewidth_outer, offset=(1,0), foreground=col[0]), pe.Normal()],  solid_capstyle='butt')\n",
    "        axs[0].plot([PPI_ints[i][0] , PPI_ints[i][1] ],[start3+i*gap, start3+i*gap], linewidth=linewidth_inner, color=lighten_color(col[2],0.6), path_effects=[pe.Stroke(linewidth=linewidth_outer, offset=(-1,0), foreground=col[1]), pe.Stroke(linewidth=linewidth_outer, offset=(1,0), foreground=col[2]), pe.Normal()],  solid_capstyle='butt')\n",
    "        axs[0].plot([classical_ints[i][0] , classical_ints[i][1] ],[start2+i*gap, start2+i*gap], linewidth=linewidth_inner, color=lighten_color(col[1],0.6), path_effects=[pe.Stroke(linewidth=linewidth_outer, offset=(-1,0), foreground=col[1]), pe.Stroke(linewidth=linewidth_outer, offset=(1,0), foreground=col[1]), pe.Normal()],  solid_capstyle='butt')\n",
    "    if i > 0:\n",
    "        axs[0].plot([CPPI_ints[i][0], CPPI_ints[i][1]],[start1+i*gap,start1+i*gap], linewidth=linewidth_inner, color= lighten_color(col[0],0.6), path_effects=[pe.Stroke(linewidth=linewidth_outer, offset=(-1,0), foreground=col[0]), pe.Stroke(linewidth=linewidth_outer, offset=(1,0), foreground=col[0]), pe.Normal()], solid_capstyle='butt')\n",
    "        axs[0].plot([PPI_ints[i][0] , PPI_ints[i][1]],[start3+i*gap, start3+i*gap], linewidth=linewidth_inner, color=lighten_color(col[2],0.6), path_effects=[pe.Stroke(linewidth=linewidth_outer, offset=(-1,0), foreground=col[1]), pe.Stroke(linewidth=linewidth_outer, offset=(1,0), foreground=col[2]), pe.Normal()], solid_capstyle='butt')\n",
    "        axs[0].plot([classical_ints[i][0] , classical_ints[i][1]],[start2+i*gap, start2+i*gap], linewidth=linewidth_inner, color=lighten_color(col[1],0.6), path_effects=[pe.Stroke(linewidth=linewidth_outer, offset=(-1,0), foreground=col[1]), pe.Stroke(linewidth=linewidth_outer, offset=(1,0), foreground=col[1]), pe.Normal()], solid_capstyle='butt')\n",
    "    \n",
    "axs[0].set_xlabel('fraction of deforested areas', fontsize=16)\n",
    "axs[0].set_yticks([])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sns.lineplot(ax=axs[1],data=final_df, x='n', y='coverage', hue='estimator', alpha=0.9, errorbar=None, marker=\"*\", markersize=14)\n",
    "sns.lineplot(ax=axs[2],data=final_df, x='n', y='width', hue='estimator', alpha=0.9, marker=\"*\", markersize=14)\n",
    "\n",
    "\n",
    "axs[1].axhline(1-alpha, color=\"#888888\", linestyle='dashed',  alpha=0.8)\n",
    "handles, labels = axs[1].get_legend_handles_labels()\n",
    "axs[2].legend(handles=handles, labels=labels)\n",
    "axs[1].get_legend().remove()\n",
    "axs[1].set_ylim([0.6,1])\n",
    "\n",
    "for i in [1,2]:\n",
    "    for j in range(3):\n",
    "        axs[i].lines[j].set_linestyle(\"--\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# axs[0].ylabel(\"\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sns.despine(top=True, right=True)\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# save plot\n",
    "plt.savefig('./deforestation_results/deforestation_intro.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7740ea4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lighten_color(color, amount=0.5):\n",
    "    \"\"\"\n",
    "    Lightens the given color by multiplying (1-luminosity) by the given amount.\n",
    "    Input can be matplotlib color string, hex string, or RGB tuple.\n",
    "\n",
    "    Examples:\n",
    "    >> lighten_color('g', 0.3)\n",
    "    >> lighten_color('#F034A3', 0.6)\n",
    "    >> lighten_color((.3,.55,.1), 0.5)\n",
    "    \"\"\"\n",
    "    import matplotlib.colors as mc\n",
    "    import colorsys\n",
    "    try:\n",
    "        c = mc.cnames[color]\n",
    "    except:\n",
    "        c = color\n",
    "    c = colorsys.rgb_to_hls(*mc.to_rgb(c))\n",
    "    return colorsys.hls_to_rgb(c[0], 1 - amount * (1 - c[1]), c[2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
