{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021c9654",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os, sys\n",
    "sys.path.insert(1, '../')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import expit\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import pdb\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5a9aec",
   "metadata": {},
   "source": [
    "## Read and preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424b8f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read raw data\n",
    "raw_df = pd.read_csv('./data.csv')\n",
    "\n",
    "# Process raw data\n",
    "df = raw_df[raw_df.Year1 != 'tdo'].copy()\n",
    "df.Year1 = df.Year1.astype(float)\n",
    "\n",
    "\n",
    "Y_all = (((df.Type1.astype(str) != 'nan') & ((df.Year1 >= 2000) & (df.Year1 <= 2015))) |\n",
    "      ((df.Type2.astype(str) != 'nan') & ((df.Year2 >= 2000) & (df.Year2 <= 2015))) |\n",
    "      ((df.Type3.astype(str) != 'nan') & ((df.Year3 >= 2000) & (df.Year3 <= 2015))) ).astype(float).to_numpy()\n",
    "\n",
    "X_all = np.stack([\n",
    "        df.tree_canopy_cover_2015/100,\n",
    "        df.tree_canopy_cover_2000/100\n",
    "    ], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744078a3",
   "metadata": {},
   "source": [
    "## Implementation of classical inference, PPI with data splitting, and cross-prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19db17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trial(X, Y, n, alpha):\n",
    "    # one trial; randomly splits data into labeled and unlabeled data and then runs baselines\n",
    "    \n",
    "    X_labeled, X_unlabeled, Y_labeled, Y_unlabeled = train_test_split(X, Y, train_size=n)\n",
    "\n",
    "    no_debiasing_int = no_debiasing_interval(X_labeled, X_unlabeled, Y_labeled, alpha) # does folds but no debiasing\n",
    "\n",
    "    no_fold_int = no_fold_interval(X_labeled, X_unlabeled, Y_labeled, alpha) \n",
    "    \n",
    "    return no_debiasing_int, no_fold_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1346f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def no_debiasing_interval(X_labeled, X_unlabeled, Y_labeled, alpha, K = 10):\n",
    "    \n",
    "    n = X_labeled.shape[0]\n",
    "    N = X_unlabeled.shape[0]\n",
    "    \n",
    "    fold_n = int(n/K)\n",
    "    \n",
    "    Yhat_unlabeled = np.zeros(N)\n",
    "    \n",
    "    for j in range(K):\n",
    "    \n",
    "        train_ind = np.delete(range(n),range(j*fold_n,(j+1)*fold_n))\n",
    "        X_train = X_labeled[train_ind,:]\n",
    "        Y_train = Y_labeled[train_ind]\n",
    "\n",
    "        # use train data to train a classifier\n",
    "        cls = HistGradientBoostingClassifier(max_iter=100,max_depth=2).fit(\n",
    "            X_train,\n",
    "            Y_train\n",
    "        )\n",
    "\n",
    "\n",
    "        Yhat_unlabeled += cls.predict_proba(X_unlabeled)[:,1]/K\n",
    "        \n",
    "    \n",
    "    thetahat = np.mean(Yhat_unlabeled)\n",
    "    \n",
    "    halfwidth = norm.ppf(1-alpha/2) * np.std(Yhat_unlabeled)/np.sqrt(N)\n",
    "    \n",
    "    return [thetahat - halfwidth, thetahat + halfwidth]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805b16a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def no_fold_interval(X_labeled, X_unlabeled, Y_labeled, alpha):\n",
    "    \n",
    "    n = X_labeled.shape[0]\n",
    "    N = X_unlabeled.shape[0]\n",
    "    \n",
    "    \n",
    "    cls = HistGradientBoostingClassifier(max_iter=100,max_depth=5).fit(\n",
    "            X_labeled,\n",
    "            Y_labeled\n",
    "        )\n",
    "    \n",
    "    Yhat_unlabeled = cls.predict_proba(X_unlabeled)[:,1]\n",
    "    Yhat_labeled = cls.predict_proba(X_labeled)[:,1]\n",
    "    \n",
    "    \n",
    "    thetahat = np.mean(Yhat_unlabeled) - np.mean(Yhat_labeled - Y_labeled) \n",
    "    \n",
    "    sigma_hat = np.sqrt(np.var(Yhat_unlabeled)/N + np.var(Yhat_labeled - Y_labeled)/n)\n",
    "    \n",
    "    halfwidth = norm.ppf(1-alpha/2) * sigma_hat\n",
    "    \n",
    "    return [thetahat - halfwidth, thetahat + halfwidth]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57dc768f",
   "metadata": {},
   "source": [
    "## Construct confidence intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4c31ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is a mean estimation problem\n",
    "\n",
    "num_trials = 10\n",
    "alpha = 0.1\n",
    "ps = [0.1, 0.2, 0.3] # fraction of data with labels\n",
    "\n",
    "theta_true = np.mean(Y_all) # we treat empirical mean over whole data set as ground truth\n",
    "\n",
    "df_list = []\n",
    "        \n",
    "# store results\n",
    "columns = [\"lb\",\"ub\",\"coverage\",\"estimator\",\"n\"]\n",
    "\n",
    "filename = \"./deforestation_results/simulation_results_heuristic.csv\"\n",
    "\n",
    "results = []\n",
    "\n",
    "for p in ps:\n",
    "        \n",
    "        n = int(p*len(Y_all))\n",
    "\n",
    "        \n",
    "        for i in range(num_trials):\n",
    "            ci_nodebiasing, ci_nofold = trial(X_all, Y_all, n, alpha)\n",
    "                \n",
    "            temp_df = pd.DataFrame(np.zeros((2,len(columns))), columns=columns)\n",
    "            temp_df.loc[0] = ci_nodebiasing[0], ci_nodebiasing[1], (ci_nodebiasing[0] <= theta_true) & (theta_true <= ci_nodebiasing[1]), \"no debiasing\", n\n",
    "            temp_df.loc[1] = ci_nofold[0], ci_nofold[1], (ci_nofold[0] <= theta_true) & (theta_true <= ci_nofold[1]), \"no folds\", n\n",
    "            results += [temp_df]\n",
    "\n",
    "df = pd.concat(results)\n",
    "df[\"width\"] = df[\"ub\"] - df[\"lb\"]\n",
    "df_list += [df]\n",
    "os.makedirs('./deforestation_results/', exist_ok=True)\n",
    "        \n",
    "final_df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "# save data\n",
    "final_df.to_csv(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f7b5a4",
   "metadata": {},
   "source": [
    "## Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540bcd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha=0.1\n",
    "col = np.array([sns.color_palette(\"Set2\")[1], sns.color_palette(\"Set2\")[2], sns.color_palette(\"Set2\")[0]])\n",
    "sns.set_theme(font_scale=1.4, style='white', palette=col, rc={'lines.linewidth': 3})\n",
    "# defaults = {'n': 100, 'beta': 0}\n",
    "fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(10,3.3))\n",
    "sns.lineplot(ax=axs[0],data=final_df, x='n', y='coverage', hue='estimator', alpha=0.9, errorbar=None, marker=\"*\", markersize=14)\n",
    "sns.lineplot(ax=axs[1],data=final_df, x='n', y='width', hue='estimator', alpha=0.9, marker=\"*\", markersize=14)\n",
    "\n",
    "axs[0].axhline(1-alpha, color=\"#888888\", linestyle='dashed', zorder=1, alpha=0.9)\n",
    "handles, labels = axs[1].get_legend_handles_labels()\n",
    "axs[1].legend(handles=handles, labels=labels)\n",
    "axs[0].get_legend().remove()\n",
    "axs[0].set_ylim([0.0,1])\n",
    "\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        axs[i].lines[j].set_linestyle(\"--\")\n",
    "\n",
    "\n",
    "sns.despine(top=True, right=True)\n",
    "plt.tight_layout()\n",
    "\n",
    "# save plot\n",
    "plt.savefig('./deforestation_results/heuristics_comparison.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad1ea02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for reading data after it has been saved\n",
    "datadir = './deforestation_results/'\n",
    "filenames = os.listdir(datadir)\n",
    "data = [ pd.read_csv(os.path.join(datadir, fn)) for fn in filenames if 'heuristic.csv' in fn ]\n",
    "final_df = pd.concat(data, axis=0, ignore_index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
