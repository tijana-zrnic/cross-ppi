{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb227a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.insert(1, '../')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.sparse import hstack\n",
    "from tqdm import tqdm\n",
    "import scipy.sparse\n",
    "from scipy.stats import norm\n",
    "import matplotlib.pyplot as plt\n",
    "import os, sys\n",
    "import folktables\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from ols_utils import get_data, transform_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371ab8db",
   "metadata": {},
   "source": [
    "## Implementation of classical inference, PPI with data splitting, and cross-prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52fb8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trial(income_features, income, n, alpha, enc):\n",
    "    # one trial; randomly splits data into labeled and unlabeled data and then runs baselines\n",
    "    \n",
    "    income_features_labeled, income_features_unlabeled, income_labeled, income_unlabeled = train_test_split(income_features, income, train_size=n)\n",
    "    \n",
    "    age_labeled = income_features_labeled['AGEP'].to_numpy()\n",
    "    age_unlabeled = income_features_unlabeled['AGEP'].to_numpy()\n",
    "    sex_labeled = income_features_labeled['SEX'].to_numpy()\n",
    "    sex_unlabeled = income_features_unlabeled['SEX'].to_numpy()\n",
    "    \n",
    "    income_labeled = income_labeled.to_numpy()\n",
    "    \n",
    "    income_features_labeled = transform_features(income_features_labeled, ft, enc)[0]\n",
    "    income_features_unlabeled = transform_features(income_features_unlabeled, ft, enc)[0]\n",
    "\n",
    "    ols_features_labeled = np.stack([age_labeled, sex_labeled], axis=1)\n",
    "    ols_features_unlabeled = np.stack([age_unlabeled, sex_unlabeled], axis=1)\n",
    "\n",
    "    classical_interval = classical_ols_interval(ols_features_labeled, income_labeled, alpha)\n",
    "    \n",
    "    pp_interval = pp_ols_interval(ols_features_labeled, income_features_labeled, ols_features_unlabeled, income_features_unlabeled, income_labeled, alpha)\n",
    "\n",
    "    cpp_interval = cross_prediction_ols_interval(ols_features_labeled, income_features_labeled, ols_features_unlabeled, income_features_unlabeled, income_labeled, alpha)\n",
    "\n",
    "    return classical_interval, pp_interval, cpp_interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edff22fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ols(features, outcome):\n",
    "    ols_coeffs = np.linalg.pinv(features).dot(outcome)\n",
    "    return ols_coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fac1472",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pp_ols_interval(Xols_labeled, X_labeled, Xols_unlabeled, X_unlabeled, Y_labeled, alpha):\n",
    "    # performs data splitting and then runs PPI\n",
    "    \n",
    "    n = X_labeled.shape[0]\n",
    "    N = X_unlabeled.shape[0]\n",
    "    \n",
    "    n_tr = int(0.2*n)\n",
    "    \n",
    "    X_train, X_val, Xols_train, Xols_val, Y_train, Y_val = train_test_split(X_labeled, Xols_labeled, Y_labeled, train_size=n_tr)\n",
    "    \n",
    "    X_train1, X_train2, y_train1, y_train2 = train_test_split(X_train, Y_train, test_size=0.2)\n",
    "    dtrain = xgb.DMatrix(X_train1, label=y_train1)\n",
    "    dtest = xgb.DMatrix(X_train2, label=y_train2)\n",
    "    \n",
    "    evallist = [(dtest, 'eval'), (dtrain, 'train')]\n",
    "    tree = xgb.train({'eta': 0.3, 'max_depth': 7, 'objective': 'reg:pseudohubererror'}, dtrain, 10000, evallist, verbose_eval=False)\n",
    "    \n",
    "    Yhat_unlabeled = tree.predict(xgb.DMatrix(X_unlabeled))\n",
    "    Yhat_val = tree.predict(xgb.DMatrix(X_val))\n",
    "    \n",
    "    thetaPP = rectified_ols_point_estimate(Xols_val, Xols_unlabeled, Y_val, Yhat_val, Yhat_unlabeled)\n",
    "\n",
    "    \n",
    "    Hessian = 1/N * Xols_unlabeled.T @ Xols_unlabeled\n",
    "    inv_Hessian = np.matrix(np.linalg.inv(Hessian))\n",
    "    \n",
    "    grads_til = np.zeros(Xols_unlabeled.shape)\n",
    "\n",
    "    for i in range(N):\n",
    "        grads_til[i,:] = (np.dot(Xols_unlabeled[i,:], thetaPP) - Yhat_unlabeled[i]) * Xols_unlabeled[i,:]\n",
    "    var_unlabeled = np.matrix(np.cov(grads_til.T))\n",
    "    \n",
    "    \n",
    "    pred_error = Yhat_val - Y_val\n",
    "    grad_diff = np.diag(pred_error) @ Xols_val\n",
    "    var_labeled = np.matrix(np.cov(grad_diff.T))\n",
    "\n",
    "    Sigma_hat = inv_Hessian @ ((n - n_tr)/N * var_unlabeled + var_labeled) @ inv_Hessian\n",
    "    \n",
    "    \n",
    "    halfwidth = norm.ppf(1-alpha/2) * np.sqrt(np.diag(Sigma_hat)/(n - n_tr))\n",
    "    \n",
    "    return [thetaPP - halfwidth, thetaPP + halfwidth]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83011804",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rectified_ols_point_estimate(X_labeled, X_unlabeled, Y_labeled, Yhat_labeled, Yhat_unlabeled):\n",
    "    # computes PPI point estimate; same subroutine is used for cross-prediction\n",
    "    \n",
    "    n = X_labeled.shape[0]\n",
    "    N = X_unlabeled.shape[0]\n",
    "    \n",
    "    \n",
    "    bias = 1/n * X_labeled.T @ (Yhat_labeled - Y_labeled)\n",
    "    XTX_inv = np.linalg.inv(1/N * X_unlabeled.T @ X_unlabeled)\n",
    "    XTy = 1/N * X_unlabeled.T @ Yhat_unlabeled\n",
    "\n",
    "    return XTX_inv @ (XTy - bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f774fba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_prediction_ols_interval(Xols_labeled, X_labeled, Xols_unlabeled, X_unlabeled, Y_labeled, alpha, K = 5):\n",
    "    # cross-prediction\n",
    "    \n",
    "    n = X_labeled.shape[0]\n",
    "    N = X_unlabeled.shape[0]\n",
    "    \n",
    "    fold_n = int(n/K)\n",
    "    \n",
    "    Yhat_labeled = np.zeros(n)\n",
    "    Yhat_unlabeled = np.zeros(N)\n",
    "    Yhat_avg_labeled = np.zeros(n)\n",
    "    \n",
    "    for j in range(K):\n",
    "    \n",
    "        X_val = X_labeled[j*fold_n:(j+1)*fold_n,:]\n",
    "        Y_val = Y_labeled[j*fold_n:(j+1)*fold_n]\n",
    "        train_ind = np.delete(range(n),range(j*fold_n,(j+1)*fold_n))\n",
    "        X_train = X_labeled[train_ind,:]\n",
    "        Y_train = Y_labeled[train_ind]\n",
    "\n",
    "        # use train data to train a tree\n",
    "        X_train1, X_train2, y_train1, y_train2 = train_test_split(X_train, Y_train, test_size=0.2)\n",
    "        dtrain = xgb.DMatrix(X_train1, label=y_train1)\n",
    "        dtest = xgb.DMatrix(X_train2, label=y_train2)\n",
    "        evallist = [(dtest, 'eval'), (dtrain, 'train')]\n",
    "        tree = xgb.train({'eta': 0.3, 'max_depth': 7, 'objective': 'reg:pseudohubererror'}, dtrain, 10000, evallist, verbose_eval=False)\n",
    "        print('cross-fit tree trained')\n",
    "\n",
    "        Yhat_unlabeled += (tree.predict(xgb.DMatrix(X_unlabeled)))/K\n",
    "        Yhat_labeled[j*fold_n:(j+1)*fold_n] = tree.predict(xgb.DMatrix(X_val))\n",
    "    \n",
    "    \n",
    "\n",
    "    thetaPP = rectified_ols_point_estimate(Xols_labeled, Xols_unlabeled, Y_labeled, Yhat_labeled, Yhat_unlabeled)\n",
    "\n",
    "\n",
    "    Sigma_hat = bootstrap_covariance(Xols_labeled, X_labeled, Xols_unlabeled, X_unlabeled, Y_labeled, n - fold_n, thetaPP)\n",
    "    \n",
    "    \n",
    "    halfwidth = norm.ppf(1-alpha/2) * np.sqrt(np.diag(Sigma_hat)/n)\n",
    "    \n",
    "    return [thetaPP - halfwidth, thetaPP + halfwidth]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28e8b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_covariance(Xols_labeled, X_labeled, Xols_unlabeled, X_unlabeled, Y_labeled, n_train, thetaPP, B = 10):\n",
    "    # estimates the asymptotic variance of cross-fitting\n",
    "    \n",
    "    \n",
    "    n = X_labeled.shape[0]\n",
    "    N = X_unlabeled.shape[0]\n",
    "\n",
    "    Yhat_labeled = np.zeros(n)\n",
    "    Yhat_unlabeled = np.zeros(N)\n",
    "    \n",
    "    d_inf = len(thetaPP)\n",
    "    \n",
    "    grad_diff = np.zeros((int((n-n_train)*B), d_inf))\n",
    "    \n",
    "    for j in range(B):\n",
    "        print(j)\n",
    "        \n",
    "        train_ind = np.random.choice(range(n),n_train)\n",
    "        X_train = X_labeled[train_ind,:]\n",
    "        Y_train = Y_labeled[train_ind]\n",
    "        \n",
    "        # use train data to train a tree\n",
    "        X_train1, X_train2, y_train1, y_train2 = train_test_split(X_train, Y_train, test_size=0.1)\n",
    "        dtrain = xgb.DMatrix(X_train1, label=y_train1)\n",
    "        dtest = xgb.DMatrix(X_train2, label=y_train2)\n",
    "        evallist = [(dtest, 'eval'), (dtrain, 'train')]\n",
    "        tree = xgb.train({'eta': 0.3, 'max_depth': 7, 'objective': 'reg:pseudohubererror'}, dtrain, 10000, evallist, verbose_eval=False)\n",
    "\n",
    "        Yhat_unlabeled += (tree.predict(xgb.DMatrix(X_unlabeled)))/B\n",
    "        \n",
    "        other_inds = np.delete(range(n), train_ind)[:n-n_train]\n",
    "        Yhat_labeled = tree.predict(xgb.DMatrix(X_labeled[other_inds, :]))\n",
    "\n",
    "        grad_diff[j*(n-n_train):(j+1)*(n-n_train), :] = np.diag(Yhat_labeled - Y_labeled[other_inds]) @ Xols_labeled[other_inds, :]\n",
    "    \n",
    "\n",
    "    Hessian = 1/N * Xols_unlabeled.T @ Xols_unlabeled\n",
    "    inv_Hessian = np.matrix(np.linalg.inv(Hessian))\n",
    "    \n",
    "    \n",
    "    grads_til = np.zeros(Xols_unlabeled.shape)\n",
    "\n",
    "    for i in range(N):\n",
    "        grads_til[i,:] = (np.dot(Xols_unlabeled[i,:], thetaPP) - Yhat_unlabeled[i]) * Xols_unlabeled[i,:]\n",
    "    var_unlabeled = np.matrix(np.cov(grads_til.T))\n",
    "    \n",
    "    var_labeled = np.matrix(np.cov(grad_diff.T))\n",
    "    \n",
    "    Sigma_hat = inv_Hessian @ (n/N * var_unlabeled + var_labeled) @ inv_Hessian\n",
    "    \n",
    "    return Sigma_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ada8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classical_ols_interval(X, Y, alpha):\n",
    "    # classical CLT interval\n",
    "    \n",
    "    n = X.shape[0]\n",
    "    thetahat = ols(X, Y)\n",
    "    Sigmainv = np.linalg.inv(1/n * X.T@X)\n",
    "    M = 1/n * (X.T*((Y - X@thetahat)**2)[None,:])@X\n",
    "    V = Sigmainv@M@Sigmainv\n",
    "    stderr = np.sqrt(np.diag(V))\n",
    "    halfwidth = norm.ppf(1-alpha/2) * stderr/np.sqrt(n)\n",
    "    return thetahat - halfwidth, thetahat + halfwidth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a312e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data. we only look at year 2019.\n",
    "features = ['AGEP','SCHL','MAR','DIS','ESP','CIT','MIG','MIL','ANC1P','NATIVITY','DEAR','DEYE','DREM','SEX','RAC1P', 'SOCP', 'COW']\n",
    "ft = np.array([\"q\", \"q\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\"])\n",
    "\n",
    "\n",
    "def get_data(year,features,outcome, randperm=True):\n",
    "    # Predict income and regress to time to work\n",
    "    data_source = folktables.ACSDataSource(survey_year=year, horizon='1-Year', survey='person')\n",
    "    acs_data = data_source.get_data(states=[\"CA\"], download=True)\n",
    "    income_features = acs_data[features].fillna(-1)\n",
    "    income = acs_data[outcome].fillna(-1)\n",
    "    employed = np.isin(acs_data['COW'], np.array([1,2,3,4,5,6,7]))\n",
    "    if randperm:\n",
    "        shuffler = np.random.permutation(income.shape[0])\n",
    "        income_features, income, employed = income_features.iloc[shuffler], income.iloc[shuffler], employed[shuffler]\n",
    "    return income_features, income, employed\n",
    "\n",
    "\n",
    "def transform_features(features, ft, enc=None):\n",
    "    c_features = features.T[ft == \"c\"].T.astype(str)\n",
    "    if enc is None:\n",
    "        enc = OneHotEncoder(handle_unknown='ignore', drop='if_binary', sparse=False)\n",
    "        enc.fit(c_features)\n",
    "    c_features = enc.transform(c_features)\n",
    "    features = scipy.sparse.csc_matrix(np.concatenate([features.T[ft == \"q\"].T.astype(float), c_features], axis=1))\n",
    "    return features, enc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101e6b95",
   "metadata": {},
   "source": [
    "## Construct confidence intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ac20ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "income_features, income, employed = get_data(year=2019, features=features, outcome='PINCP')\n",
    "income_features_enc, enc = transform_features(income_features, ft)\n",
    "\n",
    "age = income_features['AGEP'].to_numpy()\n",
    "sex = income_features['SEX'].to_numpy()\n",
    "\n",
    "true_val = ols(np.stack([age, sex], axis=1), income.to_numpy())\n",
    "\n",
    "\n",
    "num_trials = 10\n",
    "alpha = 0.1\n",
    "ps = [0.1, 0.2, 0.3] # fraction of labeled data\n",
    "\n",
    "theta_true = true_val[0]\n",
    "\n",
    "df_list = []\n",
    "        \n",
    "# store results\n",
    "columns = [\"lb\",\"ub\",\"coverage\",\"estimator\",\"n\"]\n",
    "\n",
    "filename = \"./census_results/simulation_results.csv\"\n",
    "\n",
    "results = []\n",
    "\n",
    "for p in ps:\n",
    "    \n",
    "    n = int(p*len(income))\n",
    "\n",
    "        \n",
    "    for i in range(num_trials):\n",
    "        ci, ppi, cppi = trial(income_features, income, n, alpha, enc)\n",
    "        temp_df = pd.DataFrame(np.zeros((3,len(columns))), columns=columns)\n",
    "        temp_df.loc[0] = cppi[0][0], cppi[1][0], (cppi[0][0] <= theta_true) & (theta_true <= cppi[1][0]), \"cross-prediction\", n\n",
    "        temp_df.loc[1] = ci[0][0], ci[1][0], (ci[0][0] <= theta_true) & (theta_true <= ci[1][0]), \"classical\", n\n",
    "        temp_df.loc[2] = ppi[0][0], ppi[1][0], (ppi[0][0] <= theta_true) & (theta_true <= ppi[1][0]), \"PPI\", n\n",
    "        results += [temp_df]\n",
    "        \n",
    "df = pd.concat(results)\n",
    "df[\"width\"] = df[\"ub\"] - df[\"lb\"]\n",
    "df_list += [df]\n",
    "os.makedirs('./census_results/', exist_ok=True)\n",
    "        \n",
    "final_df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "final_df.to_csv(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7964183e",
   "metadata": {},
   "source": [
    "## Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652feb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.1\n",
    "col = np.array([sns.color_palette(\"Set2\")[1], sns.color_palette(\"Set2\")[2], sns.color_palette(\"Set2\")[0]])\n",
    "sns.set_theme(font_scale=1.4, style='white', palette=col, rc={'lines.linewidth': 3})\n",
    "\n",
    "fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(10,3.3))\n",
    "sns.lineplot(ax=axs[0],data=final_df, x='n', y='coverage', hue='estimator', alpha=0.9, errorbar=None, marker=\"*\", markersize=14)\n",
    "sns.lineplot(ax=axs[1],data=final_df, x='n', y='width', hue='estimator', alpha=0.9, marker=\"*\", markersize=14)\n",
    "\n",
    "axs[0].axhline(1-alpha, color=\"#888888\", linestyle='dashed', zorder=1, alpha=0.9)\n",
    "handles, labels = axs[1].get_legend_handles_labels()\n",
    "axs[1].legend(handles=handles, labels=labels)\n",
    "axs[0].get_legend().remove()\n",
    "axs[0].set_ylim([0.5,1])\n",
    "\n",
    "for i in range(2):\n",
    "    for j in range(3):\n",
    "        axs[i].lines[j].set_linestyle(\"--\")\n",
    "\n",
    "\n",
    "sns.despine(top=True, right=True)\n",
    "plt.tight_layout()\n",
    "\n",
    "# save plot\n",
    "plt.savefig('./census_results/ols_comparison_census.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9085f66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for reading data after it has been saved\n",
    "datadir = './census_results/'\n",
    "filenames = os.listdir(datadir)\n",
    "data = [ pd.read_csv(os.path.join(datadir, fn)) for fn in filenames if 'simulation_results.' in fn ]\n",
    "final_df = pd.concat(data, axis=0, ignore_index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
